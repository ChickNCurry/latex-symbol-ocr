{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chickencurry/markup-ocr/experiments/seq2seq/encoder-decoder/code\n"
     ]
    }
   ],
   "source": [
    "%cd ../code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chickencurry/miniconda3/envs/directml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data import LatexEquationDataset, create_tokenizer, load_tokenizer, load_img_names_to_skip, curry_collate_fn, clean, get_input_token_ids, get_target_token_ids\n",
    "from model import EncoderDecoder\n",
    "from eval import get_bleu, print_statistics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import CharErrorRate, WordErrorRate, BLEUScore\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_directml\n",
    "device = torch_directml.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test_dir = \"../data/formulae/test\"\n",
    "img_train_dir = \"../data/formulae/train\"\n",
    "img_val_dir = \"../data/formulae/val\"\n",
    "equations_path = \"../data/formulae/math.txt\"\n",
    "tokenizer_path = \"../data/test_tokenizer.json\"\n",
    "img_names_to_skip_dir = \"../data/img_names_to_skip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chickencurry/miniconda3/envs/directml/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create_tokenizer(equations_path, tokenizer_path)\n",
    "tokenizer = load_tokenizer(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_img_names_to_skip(img_train_dir, img_names_to_skip_dir)\n",
    "img_names_to_skip = load_img_names_to_skip(img_names_to_skip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LatexEquationDataset(equations_path, img_train_dir, img_names_to_skip, tokenizer)\n",
    "training_dataset, validation_dataset = random_split(dataset, [0.7, 0.3])\n",
    "\n",
    "# training_dataset = LatexEquationDataset(equations_path, img_train_dir, img_names_to_skip, tokenizer)\n",
    "# validation_dataset = LatexEquationDataset(equations_path, img_val_dir, img_names_to_skip, tokenizer)\n",
    "\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=10, shuffle=False, collate_fn=curry_collate_fn(tokenizer.convert_tokens_to_ids(\"[PAD]\")))\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=1, shuffle=False, collate_fn=curry_collate_fn(tokenizer.convert_tokens_to_ids(\"[PAD]\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Delta a = { \\frac { 1 5 } { 2 } } \\pi ^ { 2 } \\int \\mathrm { d } ^ { 4 } x \\, | x | ^ { 4 } \\, \\langle \\Theta ( x ) \\, \\Theta ( 0 ) \\rangle\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "item = next(iter(training_dataloader))\n",
    "tokens = tokenizer.convert_ids_to_tokens(item[1][0].tolist(), skip_special_tokens = True)\n",
    "print(clean(\"\".join(tokens)))\n",
    "\n",
    "plt.figure()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(item[0][0].squeeze(0), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoder(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    d_feature=512,\n",
    "    d_model=256,\n",
    "    n_blocks_enc=4,\n",
    "    n_blocks_dec=4,\n",
    "    n_heads=8,\n",
    "    d_hidden=1024,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.convert_tokens_to_ids(\"[PAD]\"), label_smoothing=0.1)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    torch.inference_mode(False)\n",
    "\n",
    "    training_iterator = tqdm(training_dataloader, total=len(training_dataloader), desc=\"training epoch {}/{}\".format(epoch, num_epochs))\n",
    "\n",
    "    for img, token_ids in training_iterator:\n",
    "        # move to GPU\n",
    "        img = img.to(device)\n",
    "        input_token_ids = get_input_token_ids(token_ids, tokenizer).to(device)\n",
    "        target_token_ids = get_target_token_ids(token_ids, tokenizer).to(device)\n",
    "\n",
    "        # forward\n",
    "        logits = model(img, input_token_ids)\n",
    "        loss = criterion(logits, target_token_ids)\n",
    "\n",
    "        # collect stats\n",
    "        train_loss.append(loss.item())\n",
    "        training_iterator.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_texts = []\n",
    "target_texts = []\n",
    "\n",
    "model.eval()\n",
    "torch.inference_mode(True)\n",
    "\n",
    "validation_iterator = tqdm(validation_dataloader, total=len(validation_dataloader), desc=\"validation epoch {}/{}\".format(epoch, num_epochs))\n",
    "\n",
    "for index, (img, token_ids) in tqdm(validation_dataloader):\n",
    "    # move to GPU\n",
    "    img = img.to(device)\n",
    "    input_token_ids = get_input_token_ids(token_ids, tokenizer).to(device)\n",
    "    target_token_ids = get_target_token_ids(token_ids, tokenizer).to(device)\n",
    "\n",
    "    # forward\n",
    "    logits = model(img, input_token_ids)\n",
    "    \n",
    "    # collect stats\n",
    "    output_texts.append(tokenizer.convert_ids_to_tokens(input_token_ids[0].tolist(), skip_special_tokens = True))\n",
    "    target_texts.append(tokenizer.convert_ids_to_tokens(target_token_ids[0].tolist(), skip_special_tokens = True))\n",
    "\n",
    "bleu = BLEUScore()(output_texts, target_texts)\n",
    "wer = WordErrorRate()(output_texts, target_texts)\n",
    "cer = CharErrorRate()(output_texts, target_texts)\n",
    "\n",
    "print(f\"BLEU: {bleu}\")\n",
    "print(f\"WER: {wer}\")\n",
    "print(f\"CRE: {cer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-directml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
