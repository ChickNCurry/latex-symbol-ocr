{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.io\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_directml\n",
    "\n",
    "device = torch_directml.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test_dir = \"./data/formulae/test\"\n",
    "img_train_dir = \"./data/formulae/train\"\n",
    "img_val_dir = \"./data/formulae/val\"\n",
    "equations_path = \"./data/formulae/math.txt\"\n",
    "tokenizer_path = \"./data/my_tokenizer.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names_to_skip = [\n",
    "    '0204407.png', \n",
    "    '0204407.png', \n",
    "    '0223644.png', \n",
    "    '0210170.png', \n",
    "    '0183984.png', \n",
    "    '0207941.png', \n",
    "    '0223460.png', \n",
    "    '0227599.png', \n",
    "    '0181556.png', \n",
    "    '0161596.png', \n",
    "    '0234659.png', \n",
    "    '0206841.png', \n",
    "    '0170938.png'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatexEquationDataset(Dataset):\n",
    "    def __init__(self, equations_path: str, img_dir: str, img_names_to_skip: List[str], tokenizer):\n",
    "        super().__init__()\n",
    "        \n",
    "        with open(equations_path, \"r\") as file:\n",
    "            self._equations = file.readlines()\n",
    "\n",
    "        self._img_dir = img_dir\n",
    "        self._img_names = os.listdir(img_dir)\n",
    "        self._img_names = [x for x in self._img_names if x not in img_names_to_skip]\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._img_names)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        img_name = self._img_names[idx]\n",
    "        img_idx = int(img_name.split(\".\")[0])\n",
    "        \n",
    "        img_tensor = torchvision.io.read_image(os.path.join(self._img_dir, img_name))\n",
    "        img_tensor = img_tensor.float()\n",
    "\n",
    "        equation = self._equations[img_idx]\n",
    "        token_ids = self.tokenizer.encode(equation)\n",
    "        \n",
    "        return img_tensor, token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LatexEquationDataset(equations_path, img_train_dir, tokenizer_path, img_names_to_skip)\n",
    "\n",
    "training_dataset, validation_dataset = random_split(dataset, [0.7, 0.3])\n",
    "\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=1000, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import EncoderDecoder\n",
    "\n",
    "\n",
    "model = EncoderDecoder(32, 512, 2, tokenizer).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "\n",
    "# collect stats\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    torch.enable_grad()\n",
    "    print(\"TRAINING...\")\n",
    "\n",
    "    for index, (X_train, y_train) in enumerate(training_dataloader):\n",
    "        # move to GPU\n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "\n",
    "        # forward\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        acc = get_accuracy(y_pred, y_train)\n",
    "\n",
    "        # collect stats\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append(acc)\n",
    "        print_statistics(epoch, index, len(training_dataloader), loss.item(), acc)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    torch.no_grad()\n",
    "    print(\"TESTING...\")\n",
    "\n",
    "    for index, (X_val, y_val) in enumerate(validation_dataloader):\n",
    "        # move to GPU\n",
    "        X_val = X_val.to(device)\n",
    "        y_val = y_val.to(device)\n",
    "\n",
    "        # forward\n",
    "        y_pred = model(X_val)\n",
    "        acc = get_accuracy(y_pred, y_val)\n",
    "\n",
    "        # collect stats\n",
    "        val_acc.append(acc)\n",
    "        print_statistics(epoch, index, len(validation_dataloader), 0, acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-directml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
